{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Steps for OParl Data\n",
    "\n",
    "The main objective of the pre-processing is to extract relevant data from the OParl API endpoints and store it in Elasticsearch for visualization purposes. Below are the detailed steps to achieve this:\n",
    "\n",
    "1. **Extracting Data from the API to JSON Files**:\n",
    "   <font size=\"2\">The first step is to interact with the OParl API endpoints and retrieve the data in its raw format, typically provided in JSON. This can be done using HTTP requests or appropriate client libraries for the programming language of choice. For each relevant endpoint, the data should be fetched and saved as individual JSON files.</font>\n",
    "\n",
    "2. **Identifying and Merging Relevant Fields**:\n",
    "   <font size=\"2\">The retrieved JSON data may contain more information than needed for visualization. In this step, you'll need to identify the relevant fields required for your visualization project. These fields could include information about meetings, agenda items, participants, organizations, etc. Once identified, you can merge these fields into a single JSON file or data structure for easier processing.</font>\n",
    "\n",
    "3. **Extracting Data from Download URLs using the ExtractionWebService**:\n",
    "   <font size=\"2\">OParl data may contain references to external resources, such as documents, images, or additional data files. These resources are often linked via download URLs. To incorporate this data into your Elasticsearch index, you'll need to follow the download URLs and retrieve the relevant data using the ExtractionWebService if available. This step ensures that all necessary data is collected and linked together.</font>\n",
    "\n",
    "4. **Converting Data into _bulk API Format**:\n",
    "   <font size=\"2\">Elasticsearch offers the `_bulk` API, which allows you to perform bulk operations for efficiently storing data. In this step, you'll convert the collected and processed data into the appropriate _bulk API format. This format enables you to send multiple data entries in a single request, reducing the overhead of individual requests and speeding up the data indexing process.</font>\n",
    "\n",
    "By following these steps, you'll be able to preprocess the OParl data effectively and store it in Elasticsearch for seamless visualization and exploration of the OParl dataset. Properly processed and indexed data will enable you to build powerful visualizations and derive valuable insights from the OParl API.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracting data from the Api to json file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#available bodies\n",
    "\n",
    "person    \"https://ris.kaiserslautern.de/oparl/bodies/0001/people\"\n",
    "\n",
    "meeting    \"https://ris.kaiserslautern.de/oparl/bodies/0001/meetings\"\n",
    "\n",
    "paper    \"https://ris.kaiserslautern.de/oparl/bodies/0001/papers\"\n",
    "\n",
    "membership    \"https://ris.kaiserslautern.de/oparl/bodies/0001/memberships\"\n",
    "\n",
    "locationList    \"https://ris.kaiserslautern.de/oparl/bodies/0001/locations\"\n",
    "\n",
    "agendaItem    \"https://ris.kaiserslautern.de/oparl/bodies/0001/agendaitems\"\n",
    "\n",
    "Organisations    \"https://ris.kaiserslautern.de/oparl/bodies/0001/organizations\"\n",
    "\n",
    "consultations    \"https://ris.kaiserslautern.de/oparl/bodies/0001/consultations\"\n",
    "\n",
    "files    \"https://ris.kaiserslautern.de/oparl/bodies/0001/files\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch people data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "people_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/people'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while people_url:\n",
    "    response = requests.get(people_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        people_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        people_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/people_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'people_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch meetings data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "meetings_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/meetings'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while meetings_url:\n",
    "    response = requests.get(meetings_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        meetings_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        meetings_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/meetings_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'meetings_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch papers data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "papers_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/papers'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while papers_url:\n",
    "    response = requests.get(papers_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        papers_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        papers_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/papers_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'papers_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch memberships data from multiple pages and storing them in a json file\n",
    "\n",
    "import requests\n",
    "memberships_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/memberships'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while memberships_url:\n",
    "    response = requests.get(memberships_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        memberships_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        memberships_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/memberships_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'memberships_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch locations data from multiple pages and storing them in a json file\n",
    "\n",
    "import requests\n",
    "locations_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/locations'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while locations_url:\n",
    "    response = requests.get(locations_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        locations_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        locations_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/locations_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'locations_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch agendaitems data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "agendaitems_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/agendaitems'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while agendaitems_url:\n",
    "    response = requests.get(agendaitems_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        agendaitems_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        agendaitems_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/agendaitems_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'agendaitems_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch organisations data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "organizations_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/organizations'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while organizations_url:\n",
    "    response = requests.get(organizations_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        organizations_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        organizations_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/organizations_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'organizations_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch files data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "files_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/files'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while files_url:\n",
    "    response = requests.get(files_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        files_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        files_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/files_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'files_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fetch consultaions data from multiple pages and storing them in a json file\n",
    "\n",
    "\n",
    "consultations_url = 'https://ris.kaiserslautern.de/oparl/bodies/0001/consultations'\n",
    "data = []\n",
    "page_counter = 1\n",
    "\n",
    "while consultations_url:\n",
    "    response = requests.get(consultations_url)\n",
    "    response_data = response.json()\n",
    "    data.extend(response_data['data'])\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    if 'next' in response_data['links']:\n",
    "        consultations_url = response_data['links']['next']\n",
    "        page_counter += 1\n",
    "    else:\n",
    "        consultations_url = None\n",
    "\n",
    "# Store the data in a JSON file\n",
    "with open('/Users/ameerkhan/Downloads/Oparl_Files/consultations_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data from {page_counter} pages is stored in 'consultations_data.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
